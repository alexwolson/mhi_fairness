{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!pip install fairlearn numpy==1.24.4"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af2d84d887d015b6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fairlearn.datasets import fetch_adult"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this short workbook, we'll look at the [Adult Data Set](https://archive.ics.uci.edu/ml/datasets/adult) from the UCI Machine Learning Repository. The data set contains information about adults, including their age, work, education, and whether they make more than 50,000 dollars a year. Our task will be to predict whether an adult makes more than $50,000 a year based on the other information in the data set."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d04fdf5369ab5e1b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = fetch_adult(as_frame=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75afb8f6b3ae4970",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data.data.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af825debd72dd73e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The data set contains both categorical and numerical features. We'll need to convert the categorical features into numerical ones before we can use them in a machine learning model. We can do this using the `get_dummies` function from `pandas`. We'll also need to convert the target variable into a binary variable, where 1 indicates that the adult makes more than $50,000 a year, and 0 indicates that they make less."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c157462504252813"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X = pd.get_dummies(data.data)\n",
    "y_true = (data.target == '>50K') * 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a434ce49d8cbc26e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below, we can see that there are about twice as many male participants in the dataset as female participants:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "663fbf8580c56ed1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sex = data.data['sex']\n",
    "sex.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d59442ff2652beb",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we will train a simple decision tree classifier, and get the accuracy of our model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a675edd9a30f0fd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from fairlearn.metrics import MetricFrame\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y_true, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23c3fe3eaa317a1b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_test, classifier.predict(x_test))}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57e53a8592ea52f0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "81\\% accuracy sounds pretty good! But we should also check the fairness of our model. There are a number of different statistics we can consider to measure fairness. One common statistic is the selection rate, which is the proportion of people from a given group who are classified as positive. We can use the `MetricFrame` class from the `fairlearn` package to calculate the selection rate for each group."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f488f7dda7202a40"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "mf = MetricFrame(\n",
    "    metrics={'selection_rate': lambda y_true, y_pred: y_pred.mean()},\n",
    "    y_true=y_test,\n",
    "    y_pred=classifier.predict(x_test),\n",
    "    sensitive_features=x_test[['sex_Female']])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24a666059e006cdc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "mf.overall"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "948a4ed27de1996b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "mf.by_group"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9cadf2d0fb746d1",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "So before we even look at our model, we can see that \n",
    "\n",
    "- About 25\\% of the general population is classified as making more than 50,000 dollars a year\n",
    "- About 12\\% of those classified as female are classified as making more than 50,000 dollars a year\n",
    "- About 30\\% of those classified as male are classified as making more than 50,000 dollars a year.\n",
    "\n",
    "Next, let's compare the difference in performance for our model when we look at the different groups. Fairlearn makes this easy, and we can use any standard metric this way:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97fca8580fef2824"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "mf = MetricFrame(\n",
    "    metrics={'precision': precision_score, 'recall': recall_score, 'f1': f1_score, 'accuracy': accuracy_score},\n",
    "    y_true=y_test,\n",
    "    y_pred=classifier.predict(x_test),\n",
    "    sensitive_features=x_test[['sex_Female']])\n",
    "\n",
    "mf.by_group.plot.bar(subplots=True, layout=(2, 2), legend=False, figsize=(10, 8));"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4241733278751c5",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see here that the model has different performance for different groups. For example, the precision is better for men than for women, while the accuracy is reversed. In many sensitive applications, being able to understand and control these differences is crucial. Let's say that we now want to train a model that has the same accuracy for both groups. We can combine the `ExponentiatedGradient` class from `fairlearn` with any standard scikit-learn model to do this. Below, we'll use it to train a new decision tree classifier that has the same accuracy for male and female participants:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38731db799072678"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from fairlearn.reductions import DemographicParity, ExponentiatedGradient\n",
    "\n",
    "constraint = DemographicParity()\n",
    "classifier = DecisionTreeClassifier()\n",
    "mitigator = ExponentiatedGradient(classifier, constraint)\n",
    "mitigator.fit(x_train, y_train, sensitive_features=x_train[['sex_Female']])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84ef01f7d057f4ca",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's look at the accuracy of our new model, and compare the selection rate for each group:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a02a1f5402ced4ff"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "mf = MetricFrame(\n",
    "    metrics={'accuracy': accuracy_score, 'selection_rate': lambda y_true, y_pred: y_pred.mean()},\n",
    "    y_true=y_test,\n",
    "    y_pred=mitigator.predict(x_test),\n",
    "    sensitive_features=x_test['sex_Female']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "998c16ff2b5c6116",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "mf.overall"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6531bacb20c2a68c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "mf.by_group"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "caa6fee286843417",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that not only is the accuracy much closer between the two groups, but the selection rate (i.e. the proportion of people classified as making more than 50,000 dollars a year) is also much closer. This is a simple example, but it shows how we can use the `fairlearn` package to understand and control the fairness of our machine learning models.\n",
    "\n",
    "Fairlearn provides many other tools for understanding and controlling fairness in machine learning models. For example, we can use the `fairlearn` package to understand the trade-offs between fairness and accuracy, and to visualize the performance of our model. We can also use it to understand the impact of our model on different groups, and to compare the performance of different models. For more information, see the [fairlearn documentation](https://fairlearn.github.io/)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "383b4514d03957f4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
